{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63772d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe46d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6acfcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/sample_data/nlp.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9148/2419648244.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/sample_data/nlp.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/nlp.txt'"
     ]
    }
   ],
   "source": [
    "f = open('', 'r', errors = 'ignore')\n",
    "\n",
    "text = f.read()\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d690bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddf021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3438b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "print(sent_tokens)\n",
    "print(len(sent_tokens))\n",
    "\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "print(word_tokens)\n",
    "\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "def LemToken(tokens):\n",
    "  return [lemma.lemmatize(token) for token in tokens]\n",
    "\n",
    "remove_puct = dict((ord(punct),None) for punct in string.punctuation)\n",
    "\n",
    "\n",
    "def lemnormalize(text):\n",
    "  return LemToken(nltk.word_tokenize(text.lower().translate(remove_puct)))\n",
    "\n",
    "greetings_inputs = ('hello','hi','greetings','sup',\"what's up\",\"hey\",\"hi good day\", )\n",
    "\n",
    "greeting_response = [\"hi\",\"hey\",\"hi there\", 'Hello',\"Hi welcome to the NLP \"]\n",
    "\n",
    "def greeting(sent):\n",
    "  for word in sent.split():\n",
    "    if word.lower() in greetings_inputs:\n",
    "      return random.choice(greeting_response)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def response(user_response):\n",
    "  bot_response = ''\n",
    "  sent_tokens.append(user_response)\n",
    "  word_vec = TfidfVectorizer(tokenizer=lemnormalize,stop_words='english')\n",
    "  word_vec1 = word_vec.fit_transform(sent_tokens)\n",
    "  vals = cosine_similarity(word_vec1[-1],word_vec1)\n",
    "  idx = vals.argsort()[0][-2]\n",
    "  flat = vals.flatten()\n",
    "  flat.sort()\n",
    "  req_word_vec = flat[-2]\n",
    "  if req_word_vec == 0:\n",
    "    bot_response = bot_response + \"I am sorry , I dont understand you\"\n",
    "    return bot_response\n",
    "  else:\n",
    "    bot_response = bot_response+sent_tokens[idx]\n",
    "    return bot_response\n",
    "\n",
    "flag = True\n",
    "print(\"Remo: My name is Remo. I will answer your questions about NLP. if you want to exit , type Quit,bye,exit\") \n",
    "\n",
    "while (flag == True):\n",
    "  user_response = input()\n",
    "  user_response = user_response.lower()\n",
    "  #list_ = ['quit','bye','exit']\n",
    "  if  (user_response != \"exit\"):\n",
    "    print('true')\n",
    "    if (user_response == 'thanks' or user_response == 'thank you'):\n",
    "      flag = False\n",
    "      print(\"Remo: you are welcome\")\n",
    "\n",
    "    else:\n",
    "      if (greeting(user_response) != None):\n",
    "        print(\"Remo:\" + greeting(user_response))\n",
    "\n",
    "      else:\n",
    "        print(\"Remo\" , end = \"\")\n",
    "        print(response(user_response))\n",
    "        sent_tokens.remove(user_response)\n",
    "\n",
    "  else:\n",
    "    flag = False\n",
    "    print(\"Remo : Bye! Take care\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
